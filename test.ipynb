{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1522e38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import google.generativeai as genai\n",
    "import json\n",
    "import time\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e3d201",
   "metadata": {},
   "source": [
    "# JSON to CSV Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "610950cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_edges_to_csv(input_file, output_file):\n",
    "    \"\"\"\n",
    "    Parse edges.jsonl and extract subject, predicate, and object columns to CSV\n",
    "    \"\"\"\n",
    "    with open(input_file, 'r') as jsonl_file, open(output_file, 'w', newline='') as csv_file:\n",
    "        writer = csv.writer(csv_file)\n",
    "        \n",
    "        # Write header\n",
    "        writer.writerow(['subject', 'predicate', 'object'])\n",
    "        \n",
    "        # Process each line in the JSONL file\n",
    "        for line in jsonl_file:\n",
    "            try:\n",
    "                data = json.loads(line.strip())\n",
    "                subject = data.get('subject', '')\n",
    "                predicate = data.get('predicate', '')\n",
    "                obj = data.get('object', '')\n",
    "                \n",
    "                writer.writerow([subject, predicate, obj])\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"Skipping invalid JSON line: {line}\")\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ccf30118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file created: edges_output.csv\n"
     ]
    }
   ],
   "source": [
    "input_file = \"./data/example_edges.jsonl\"\n",
    "output_file = \"edges_output.csv\"\n",
    "    \n",
    "parse_edges_to_csv(input_file, output_file)\n",
    "print(f\"CSV file created: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fbaa0ca",
   "metadata": {},
   "source": [
    "# Sub graph Preparation (random predicate removal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "15ff831e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_chunk_and_remove_predicates(input_csv, chunk_size=100, predicate_removal_percent=50, output_file='modified_chunk.csv'):\n",
    "    \"\"\"\n",
    "    Select a random chunk from the CSV and remove a percentage of edges for each unique predicate.\n",
    "    \n",
    "    Args:\n",
    "        input_csv: Path to the input CSV file\n",
    "        chunk_size: Number of rows to select (default: 100)\n",
    "        predicate_removal_percent: Percentage of edges to remove for each unique predicate (default: 50)\n",
    "        output_file: Path to save the modified chunk\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (original_chunk_df, modified_chunk_df)\n",
    "    \"\"\"\n",
    "    # Read the CSV\n",
    "    df = pd.read_csv(input_csv)\n",
    "    \n",
    "    # Select a random chunk\n",
    "    if chunk_size >= len(df):\n",
    "        chunk_df = df.copy()\n",
    "    else:\n",
    "        start_idx = random.randint(0, len(df) - chunk_size)\n",
    "        chunk_df = df.iloc[start_idx:start_idx + chunk_size].copy()\n",
    "    \n",
    "    # Store original chunk\n",
    "    original_chunk = chunk_df.copy()\n",
    "    modified_chunk = chunk_df.copy()\n",
    "    \n",
    "    # Get unique predicates in the chunk\n",
    "    unique_predicates = modified_chunk['predicate'].unique()\n",
    "    \n",
    "    total_removed = 0\n",
    "    \n",
    "    # Remove specified percentage of edges for each unique predicate\n",
    "    for predicate in unique_predicates:\n",
    "        predicate_indices = modified_chunk[modified_chunk['predicate'] == predicate].index.tolist()\n",
    "        num_to_remove_pred = int(len(predicate_indices) * (predicate_removal_percent / 100))\n",
    "        \n",
    "        if num_to_remove_pred > 0:\n",
    "            indices_to_remove_pred = random.sample(predicate_indices, num_to_remove_pred)\n",
    "            modified_chunk.loc[indices_to_remove_pred, 'predicate'] = ''\n",
    "            total_removed += num_to_remove_pred\n",
    "    \n",
    "    # Save modified chunk to CSV\n",
    "    modified_chunk.to_csv(output_file, index=False)\n",
    "    \n",
    "    print(f\"Original chunk size: {len(original_chunk)}\")\n",
    "    print(f\"Removed {predicate_removal_percent}% of edges for each unique predicate\")\n",
    "    print(f\"Total edges with predicates removed: {total_removed}\")\n",
    "    print(f\"Modified chunk size: {len(modified_chunk)}\")\n",
    "    print(f\"Modified chunk saved to: {output_file}\")\n",
    "    \n",
    "    return original_chunk, modified_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0a9d9169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original chunk size: 100\n",
      "Removed 50% of edges for each unique predicate\n",
      "Total edges with predicates removed: 40\n",
      "Modified chunk size: 100\n",
      "Modified chunk saved to: modified_chunk_50%_removed.csv\n"
     ]
    }
   ],
   "source": [
    "original, modified = select_chunk_and_remove_predicates(\n",
    "    'edges_output.csv',\n",
    "    chunk_size=100,\n",
    "    predicate_removal_percent=50,\n",
    "    output_file='modified_chunk_50%_removed.csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3ae98e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Chunk:\n",
      "          subject                 predicate         object\n",
      "1041   CL:0000576          biolink:produces  NCBIGene:3553\n",
      "1042   CL:0000576          biolink:produces  NCBIGene:3553\n",
      "1043  CHEBI:30411  biolink:applied_to_treat  MONDO:0002012\n",
      "1044  CHEBI:17303            biolink:causes  UMLS:C0040210\n",
      "1045  CHEBI:17303            biolink:causes  UMLS:C0040210\n",
      "\n",
      "Modified Chunk:\n",
      "          subject       predicate         object\n",
      "1041   CL:0000576                  NCBIGene:3553\n",
      "1042   CL:0000576                  NCBIGene:3553\n",
      "1043  CHEBI:30411                  MONDO:0002012\n",
      "1044  CHEBI:17303  biolink:causes  UMLS:C0040210\n",
      "1045  CHEBI:17303                  UMLS:C0040210\n",
      "\n",
      "Removed Rows:\n"
     ]
    }
   ],
   "source": [
    "print(\"Original Chunk:\")\n",
    "print(original.head())\n",
    "print(\"\\nModified Chunk:\")\n",
    "print(modified.head())\n",
    "print(\"\\nRemoved Rows:\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff92acce",
   "metadata": {},
   "source": [
    "# Random Edge Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3d1a251a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to randomly assign edges to nodes from the list of unique predicates \n",
    "def randomly_assign_edges(input_csv, unique_predicates, output_file='randomly_assigned_edges.csv'):\n",
    "    \"\"\"\n",
    "    Randomly assign edges to nodes from the list of unique predicates and save to new CSV.\n",
    "    \n",
    "    Args:\n",
    "        input_csv: Path to the input CSV file\n",
    "        unique_predicates: List of unique predicates\n",
    "        output_file: Path to save the new CSV with randomly assigned edges\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(input_csv)\n",
    "    \n",
    "    # Fill empty predicates with random choices from unique_predicates\n",
    "    for idx, row in df.iterrows():\n",
    "        if pd.isna(row['predicate']) or row['predicate'] == '' or str(row['predicate']).strip() == '':\n",
    "            df.at[idx, 'predicate'] = random.choice(unique_predicates)\n",
    "    \n",
    "    # Save to new CSV\n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(f\"Randomly assigned edges saved to: {output_file}\")\n",
    "    \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ace49410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicates found:\n",
      "['biolink:causes' 'biolink:affects' 'biolink:negatively_correlated_with'\n",
      " 'biolink:has_part' 'biolink:preventative_for_condition'\n",
      " 'biolink:positively_correlated_with' 'biolink:regulates'\n",
      " 'biolink:target_for' 'biolink:decreases_response_to' 'biolink:treats'\n",
      " 'biolink:occurs_in' 'biolink:manifestation_of' 'biolink:correlated_with'\n",
      " 'biolink:has_participant' 'biolink:composed_primarily_of'\n",
      " 'biolink:contributes_to' 'biolink:applied_to_treat' 'biolink:disrupts'\n",
      " 'biolink:develops_from' 'biolink:related_to'\n",
      " 'biolink:acts_upstream_of_negative_effect' 'biolink:has_phenotype'\n",
      " 'biolink:produces' 'biolink:subclass_of'\n",
      " 'biolink:acts_upstream_of_positive_effect' 'biolink:located_in'\n",
      " 'biolink:directly_physically_interacts_with' 'biolink:precedes'\n",
      " 'biolink:associated_with_increased_likelihood_of'\n",
      " 'biolink:physically_interacts_with' 'biolink:interacts_with'\n",
      " 'biolink:in_taxon' 'biolink:has_input']\n",
      "33\n",
      "Randomly assigned edges saved to: randomly_assigned_edges.csv\n"
     ]
    }
   ],
   "source": [
    "# list of all unique predicates in the dataset which are not empty\n",
    "unique_predicates = modified['predicate'].unique()\n",
    "unique_predicates = unique_predicates[unique_predicates != '']\n",
    "print(\"Unique predicates found:\")\n",
    "print(unique_predicates)\n",
    "print(len(unique_predicates))\n",
    "\n",
    "# Run the improved function\n",
    "result_df = randomly_assign_edges('modified_chunk_50%_removed.csv', unique_predicates, output_file='randomly_assigned_edges.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51826422",
   "metadata": {},
   "source": [
    "# Gemini LLM Edge Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "33b6ff5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "api = \"AIzaSyCQVqiw_JyVbMrko4TpplqS0bf2GJCtgr8\"\n",
    "\n",
    "def fill_missing_predicates_llm_base(input_df, unique_predicates, output_file='llm_filled_predicates.csv', \n",
    "                                    metrics_file='llm_metrics.json', responses_file='llm_responses.json'):\n",
    "    \"\"\"\n",
    "    Use Gemini API to fill in missing predicates in the DataFrame using a single batch prompt.\n",
    "    \n",
    "    Args:\n",
    "        input_df: DataFrame with potential missing predicates\n",
    "        unique_predicates: List of unique predicates to choose from\n",
    "        output_file: Path to save the new CSV with LLM filled predicates\n",
    "        metrics_file: Path to save metrics about the LLM usage\n",
    "        responses_file: Path to save all LLM responses for analysis\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (filled_df, metrics, responses)\n",
    "    \"\"\"\n",
    "    # Configure Gemini API\n",
    "    genai.configure(api_key=api)\n",
    "    model = genai.GenerativeModel('gemini-2.5-flash')\n",
    "    \n",
    "    df = input_df.copy()\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Find all empty predicate rows\n",
    "    empty_mask = df['predicate'].isna() | (df['predicate'] == '') | (df['predicate'].str.strip() == '')\n",
    "    empty_indices = df[empty_mask].index.tolist()\n",
    "    empty_count = len(empty_indices)\n",
    "    \n",
    "    print(f\"Found {empty_count} empty predicates to fill\")\n",
    "    \n",
    "    if empty_count == 0:\n",
    "        print(\"No empty predicates found!\")\n",
    "        return df, {}, []\n",
    "    \n",
    "    # Build single large prompt with all missing predicates\n",
    "    predicate_list = ', '.join(unique_predicates)\n",
    "    \n",
    "    batch_prompt = f\"\"\"You are a biomedical knowledge graph expert. Complete the missing predicates for these triples.\n",
    "\n",
    "Available predicates: {predicate_list}\n",
    "\n",
    "Instructions: For each numbered triple, respond with ONLY the most appropriate predicate from the list above.\n",
    "\n",
    "Triples to complete:\n",
    "\"\"\"\n",
    "    \n",
    "    # Add all empty predicate cases to the prompt\n",
    "    case_mapping = {}  # Maps case number to dataframe index\n",
    "    for case_num, idx in enumerate(empty_indices, 1):\n",
    "        row = df.iloc[idx]\n",
    "        batch_prompt += f\"{case_num}. Subject: {row['subject']} | Object: {row['object']}\\n\"\n",
    "        case_mapping[case_num] = idx\n",
    "    \n",
    "    batch_prompt += f\"\"\"\n",
    "Expected response format:\n",
    "1. predicate_name\n",
    "2. predicate_name\n",
    "3. predicate_name\n",
    "...\n",
    "\n",
    "Respond with ONLY the numbered list of predicates, nothing else.\"\"\"\n",
    "\n",
    "    print(f\"Sending batch request for {empty_count} predicates...\")\n",
    "    \n",
    "    llm_filled_count = 0\n",
    "    fallback_count = 0\n",
    "    successful_requests = 0\n",
    "    failed_requests = 0\n",
    "    \n",
    "    try:\n",
    "        # Single API request for all missing predicates\n",
    "        response = model.generate_content(\n",
    "            batch_prompt,\n",
    "            generation_config=genai.types.GenerationConfig(\n",
    "                max_output_tokens=empty_count * 10,  # Adjust based on number of predicates\n",
    "                temperature=0.3,\n",
    "                candidate_count=1\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        response_text = response.text.strip()\n",
    "        print(\"✓ Batch API request successful\")\n",
    "        successful_requests = 1\n",
    "        \n",
    "        # Parse the response to extract individual predicates\n",
    "        response_lines = response_text.split('\\n')\n",
    "        \n",
    "        # Use regex to extract numbered responses\n",
    "        predicate_suggestions = {}\n",
    "        for line in response_lines:\n",
    "            line = line.strip()\n",
    "            if line:\n",
    "                # Match patterns like \"1. biolink:treats\" or \"1) biolink:treats\" or \"1 biolink:treats\"\n",
    "                match = re.match(r'^(\\d+)[\\.\\)\\s]+(.+)', line)\n",
    "                if match:\n",
    "                    case_num = int(match.group(1))\n",
    "                    suggested_predicate = match.group(2).strip()\n",
    "                    \n",
    "                    # Clean up the suggestion (remove quotes, extra text)\n",
    "                    suggested_predicate = suggested_predicate.replace('\"', '').replace(\"'\", \"\")\n",
    "                    \n",
    "                    # Try exact match first\n",
    "                    if suggested_predicate in unique_predicates:\n",
    "                        predicate_suggestions[case_num] = suggested_predicate\n",
    "                    else:\n",
    "                        # Try partial matching\n",
    "                        for predicate in unique_predicates:\n",
    "                            if predicate in suggested_predicate or suggested_predicate in predicate:\n",
    "                                predicate_suggestions[case_num] = predicate\n",
    "                                break\n",
    "        \n",
    "        print(f\"✓ Successfully parsed {len(predicate_suggestions)} predicates from response\")\n",
    "        \n",
    "        # Apply the suggestions to the dataframe\n",
    "        for case_num, idx in case_mapping.items():\n",
    "            if case_num in predicate_suggestions:\n",
    "                suggested_predicate = predicate_suggestions[case_num]\n",
    "                df.at[idx, 'predicate'] = suggested_predicate\n",
    "                llm_filled_count += 1\n",
    "                print(f\"✓ Row {idx}: Filled with '{suggested_predicate}'\")\n",
    "            else:\n",
    "                # Fallback to random selection\n",
    "                fallback_predicate = random.choice(unique_predicates)\n",
    "                df.at[idx, 'predicate'] = fallback_predicate\n",
    "                fallback_count += 1\n",
    "                print(f\"⚠ Row {idx}: No suggestion found, used random '{fallback_predicate}'\")\n",
    "        \n",
    "        # Estimate token usage\n",
    "        input_tokens = len(batch_prompt.split()) * 1.3\n",
    "        output_tokens = len(response_text.split()) * 1.3\n",
    "        \n",
    "        # Store response details\n",
    "        responses = [{\n",
    "            'batch_request': True,\n",
    "            'total_cases': empty_count,\n",
    "            'prompt': batch_prompt,\n",
    "            'response_text': response_text,\n",
    "            'parsed_suggestions': predicate_suggestions,\n",
    "            'case_mapping': case_mapping,\n",
    "            'success': True,\n",
    "            'estimated_input_tokens': input_tokens,\n",
    "            'estimated_output_tokens': output_tokens\n",
    "        }]\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"✗ Batch API request failed: {e}\")\n",
    "        failed_requests = 1\n",
    "        \n",
    "        # Fallback: fill all with random predicates\n",
    "        for idx in empty_indices:\n",
    "            fallback_predicate = random.choice(unique_predicates)\n",
    "            df.at[idx, 'predicate'] = fallback_predicate\n",
    "            fallback_count += 1\n",
    "        \n",
    "        responses = [{\n",
    "            'batch_request': True,\n",
    "            'total_cases': empty_count,\n",
    "            'prompt': batch_prompt,\n",
    "            'error': str(e),\n",
    "            'success': False,\n",
    "            'fallback_used': True\n",
    "        }]\n",
    "        \n",
    "        input_tokens = len(batch_prompt.split()) * 1.3\n",
    "        output_tokens = 0\n",
    "    \n",
    "    end_time = time.time()\n",
    "    total_time = end_time - start_time\n",
    "    \n",
    "    # Create metrics summary\n",
    "    metrics = {\n",
    "        'total_empty_predicates': empty_count,\n",
    "        'llm_filled_count': llm_filled_count,\n",
    "        'fallback_count': fallback_count,\n",
    "        'successful_requests': successful_requests,\n",
    "        'failed_requests': failed_requests,\n",
    "        'total_requests': successful_requests + failed_requests,\n",
    "        'success_rate': successful_requests / (successful_requests + failed_requests) if (successful_requests + failed_requests) > 0 else 0,\n",
    "        'llm_success_rate': llm_filled_count / empty_count if empty_count > 0 else 0,\n",
    "        'total_processing_time_seconds': total_time,\n",
    "        'estimated_total_input_tokens': input_tokens,\n",
    "        'estimated_total_output_tokens': output_tokens,\n",
    "        'estimated_total_tokens': input_tokens + output_tokens,\n",
    "        'batch_processing': True,\n",
    "        'speed_improvement': f\"~{empty_count}x faster than individual requests\"\n",
    "    }\n",
    "    \n",
    "    # Save files\n",
    "    df.to_csv(output_file, index=False)\n",
    "    \n",
    "    with open(metrics_file, 'w') as f:\n",
    "        json.dump(metrics, f, indent=2)\n",
    "    \n",
    "    with open(responses_file, 'w') as f:\n",
    "        json.dump(responses, f, indent=2)\n",
    "    \n",
    "    # Print summary\n",
    "    print(f\"\\n=== Batch LLM Processing Complete ===\")\n",
    "    print(f\"LLM filled predicates saved to: {output_file}\")\n",
    "    print(f\"Total predicates filled by LLM: {llm_filled_count}/{empty_count}\")\n",
    "    print(f\"Fallback (random) assignments: {fallback_count}\")\n",
    "    print(f\"LLM success rate: {metrics['llm_success_rate']:.2%}\")\n",
    "    print(f\"Total processing time: {total_time:.2f} seconds\")\n",
    "    print(f\"Estimated tokens used: {int(input_tokens + output_tokens)}\")\n",
    "    print(f\"Speed improvement: ~{empty_count}x faster than individual requests!\")\n",
    "    print(f\"Metrics saved to: {metrics_file}\")\n",
    "    print(f\"Responses saved to: {responses_file}\")\n",
    "    \n",
    "    return df, metrics, responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a780b0dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame shape: (100, 3)\n",
      "Index range: 0 to 99\n",
      "Found 40 empty predicates to fill\n",
      "Sending batch request for 40 predicates...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1759381559.366299  710520 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Batch API request successful\n",
      "✓ Successfully parsed 40 predicates from response\n",
      "✓ Row 0: Filled with 'biolink:has_part'\n",
      "✓ Row 1: Filled with 'biolink:has_part'\n",
      "✓ Row 2: Filled with 'biolink:treats'\n",
      "✓ Row 4: Filled with 'biolink:causes'\n",
      "✓ Row 5: Filled with 'biolink:contributes_to'\n",
      "✓ Row 7: Filled with 'biolink:has_phenotype'\n",
      "✓ Row 9: Filled with 'biolink:contributes_to'\n",
      "✓ Row 10: Filled with 'biolink:has_participant'\n",
      "✓ Row 12: Filled with 'biolink:subclass_of'\n",
      "✓ Row 13: Filled with 'biolink:occurs_in'\n",
      "✓ Row 18: Filled with 'biolink:directly_physically_interacts_with'\n",
      "✓ Row 21: Filled with 'biolink:regulates'\n",
      "✓ Row 22: Filled with 'biolink:associated_with_increased_likelihood_of'\n",
      "✓ Row 24: Filled with 'biolink:produces'\n",
      "✓ Row 27: Filled with 'biolink:has_input'\n",
      "✓ Row 35: Filled with 'biolink:has_phenotype'\n",
      "✓ Row 38: Filled with 'biolink:manifestation_of'\n",
      "✓ Row 43: Filled with 'biolink:directly_physically_interacts_with'\n",
      "✓ Row 47: Filled with 'biolink:contributes_to'\n",
      "✓ Row 51: Filled with 'biolink:has_input'\n",
      "✓ Row 52: Filled with 'biolink:has_input'\n",
      "✓ Row 53: Filled with 'biolink:regulates'\n",
      "✓ Row 58: Filled with 'biolink:precedes'\n",
      "✓ Row 60: Filled with 'biolink:manifestation_of'\n",
      "✓ Row 62: Filled with 'biolink:contributes_to'\n",
      "✓ Row 63: Filled with 'biolink:has_input'\n",
      "✓ Row 66: Filled with 'biolink:target_for'\n",
      "✓ Row 67: Filled with 'biolink:directly_physically_interacts_with'\n",
      "✓ Row 72: Filled with 'biolink:occurs_in'\n",
      "✓ Row 73: Filled with 'biolink:treats'\n",
      "✓ Row 75: Filled with 'biolink:contributes_to'\n",
      "✓ Row 76: Filled with 'biolink:related_to'\n",
      "✓ Row 77: Filled with 'biolink:disrupts'\n",
      "✓ Row 78: Filled with 'biolink:acts_upstream_of_positive_effect'\n",
      "✓ Row 84: Filled with 'biolink:has_participant'\n",
      "✓ Row 85: Filled with 'biolink:has_participant'\n",
      "✓ Row 86: Filled with 'biolink:target_for'\n",
      "✓ Row 87: Filled with 'biolink:target_for'\n",
      "✓ Row 91: Filled with 'biolink:contributes_to'\n",
      "✓ Row 96: Filled with 'biolink:subclass_of'\n",
      "\n",
      "=== Batch LLM Processing Complete ===\n",
      "LLM filled predicates saved to: gemini_filled_test.csv\n",
      "Total predicates filled by LLM: 40/40\n",
      "Fallback (random) assignments: 0\n",
      "LLM success rate: 100.00%\n",
      "Total processing time: 48.79 seconds\n",
      "Estimated tokens used: 530\n",
      "Speed improvement: ~40x faster than individual requests!\n",
      "Metrics saved to: gemini_metrics_test.json\n",
      "Responses saved to: gemini_responses_test.json\n"
     ]
    }
   ],
   "source": [
    "# Test the LLM function with a subset of data first - Fix the indexing issue\n",
    "test_df = modified.copy().reset_index(drop=True)  # Reset index to 0, 1, 2, 3...\n",
    "\n",
    "print(f\"DataFrame shape: {test_df.shape}\")\n",
    "print(f\"Index range: {test_df.index.min()} to {test_df.index.max()}\")\n",
    "\n",
    "filled_df, metrics, responses = fill_missing_predicates_llm_base(\n",
    "    test_df,\n",
    "    unique_predicates,\n",
    "    output_file='gemini_filled_test.csv',\n",
    "    metrics_file='gemini_metrics_test.json',\n",
    "    responses_file='gemini_responses_test.json'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81942dca",
   "metadata": {},
   "source": [
    "# in progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8a962d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection already exists, getting existing collection...\n",
      "Retrieved existing collection: pubtator_data\n",
      "Collection currently has 100 documents\n",
      "Collection already contains data. Skipping file processing.\n",
      "Retrieved documents:\n",
      "Document: 40757000\tGene\t1791\tTdT|Terminal deoxynucleotidyl transferase\tPubTator3... (Source: gene2pubtator3.gz)\n",
      "Document: 40757000\tGene\t374\tAREG|amphiregulin\tPubTator3... (Source: gene2pubtator3.gz)\n",
      "Document: 40757000\tGene\t108155\tOGT\tPubTator3... (Source: gene2pubtator3.gz)\n",
      "Document: 40757000\tGene\t9332\tCD163\tPubTator3... (Source: gene2pubtator3.gz)\n",
      "Document: 40757000\tGene\t283871\tPgp\tPubTator3... (Source: gene2pubtator3.gz)\n",
      "Collection currently has 100 documents\n",
      "Collection already contains data. Skipping file processing.\n",
      "Retrieved documents:\n",
      "Document: 40757000\tGene\t1791\tTdT|Terminal deoxynucleotidyl transferase\tPubTator3... (Source: gene2pubtator3.gz)\n",
      "Document: 40757000\tGene\t374\tAREG|amphiregulin\tPubTator3... (Source: gene2pubtator3.gz)\n",
      "Document: 40757000\tGene\t108155\tOGT\tPubTator3... (Source: gene2pubtator3.gz)\n",
      "Document: 40757000\tGene\t9332\tCD163\tPubTator3... (Source: gene2pubtator3.gz)\n",
      "Document: 40757000\tGene\t283871\tPgp\tPubTator3... (Source: gene2pubtator3.gz)\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import gzip\n",
    "import chromadb\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import uuid\n",
    "\n",
    "# URLs for the .gz files (tool descriptions)\n",
    "urls = [\n",
    "    # \"https://ftp.ncbi.nlm.nih.gov/pub/lu/PubTator3/bioconcepts2pubtator3.gz\",\n",
    "    \"https://ftp.ncbi.nlm.nih.gov/pub/lu/PubTator3/gene2pubtator3.gz\"\n",
    "]\n",
    "\n",
    "local_files = [\"gene2pubtator3.gz\"]\n",
    "\n",
    "# Function to download the .gz files from URLs\n",
    "def download_file(url, local_path):\n",
    "    response = requests.get(url)\n",
    "    with open(local_path, 'wb') as f:\n",
    "        f.write(response.content)\n",
    "    print(f\"Downloaded file: {local_path}\")\n",
    "\n",
    "# Download the files\n",
    "# for url, local_file in zip(urls, local_files):\n",
    "#     download_file(url, local_file)\n",
    "\n",
    "# Initialize ChromaDB client (new method)\n",
    "client = chromadb.Client()\n",
    "\n",
    "# Create or get the collection - handle existing collection\n",
    "try:\n",
    "    collection = client.create_collection(\"pubtator_data\")\n",
    "    print(\"Created new collection: pubtator_data\")\n",
    "except Exception as e:\n",
    "    if \"already exists\" in str(e):\n",
    "        print(\"Collection already exists, getting existing collection...\")\n",
    "        collection = client.get_collection(\"pubtator_data\")\n",
    "        print(\"Retrieved existing collection: pubtator_data\")\n",
    "    else:\n",
    "        raise e\n",
    "\n",
    "# Load the transformer model for embedding\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Initialize text splitter (chunk text into smaller pieces)\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "\n",
    "def embed_text(text):\n",
    "    \"\"\"Embed text into vector using pre-trained model.\"\"\"\n",
    "    embedding = model.encode(text)\n",
    "    return embedding\n",
    "\n",
    "# Function to read and process the .gz files\n",
    "def process_gz_file(file_path):\n",
    "    with gzip.open(file_path, 'rt') as f:\n",
    "        return f.readlines()\n",
    "\n",
    "# Check if collection already has data\n",
    "existing_count = collection.count()\n",
    "print(f\"Collection currently has {existing_count} documents\")\n",
    "\n",
    "# Only process files if collection is empty or you want to add more data\n",
    "if existing_count == 0:\n",
    "    print(\"Collection is empty, processing files...\")\n",
    "    # Process and insert the data into ChromaDB\n",
    "    for file in local_files:\n",
    "        print(f\"Processing file: {file}\")\n",
    "        lines = process_gz_file(file)\n",
    "        \n",
    "        # Process first 100 lines for testing (remove this limit for full processing)\n",
    "        lines = lines[:100]  # Limit for testing\n",
    "        \n",
    "        # Split lines into smaller chunks\n",
    "        for line_idx, line in enumerate(lines):\n",
    "            chunks = splitter.split_text(line.strip())  # Split long descriptions into chunks\n",
    "            \n",
    "            # For each chunk, generate embedding and store in ChromaDB\n",
    "            for chunk_idx, chunk in enumerate(chunks):\n",
    "                if chunk.strip():  # Only process non-empty chunks\n",
    "                    embedding = embed_text(chunk)\n",
    "                    unique_id = f\"{file}_{line_idx}_{chunk_idx}_{str(uuid.uuid4())[:8]}\"\n",
    "                    \n",
    "                    # Add document and metadata (such as source file and chunk position) to ChromaDB\n",
    "                    collection.add(\n",
    "                        ids=[unique_id],\n",
    "                        documents=[chunk],\n",
    "                        metadatas=[{\"source\": file, \"line_idx\": line_idx, \"chunk_idx\": chunk_idx}],\n",
    "                        embeddings=[embedding.tolist()]\n",
    "                    )\n",
    "    \n",
    "    print(\"Data inserted into ChromaDB.\")\n",
    "else:\n",
    "    print(\"Collection already contains data. Skipping file processing.\")\n",
    "\n",
    "# Query ChromaDB for relevant documents (example query)\n",
    "query = \"What is gene expression in biological research?\"\n",
    "query_embedding = embed_text(query)\n",
    "\n",
    "# Perform the retrieval to get top-k similar documents\n",
    "results = collection.query(\n",
    "    query_embeddings=[query_embedding.tolist()],\n",
    "    n_results=5  # Retrieve top 5 similar documents\n",
    ")\n",
    "\n",
    "print(\"Retrieved documents:\")\n",
    "for doc, metadata in zip(results[\"documents\"][0], results[\"metadatas\"][0]):\n",
    "    print(f\"Document: {doc[:200]}... (Source: {metadata['source']})\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f6ef7ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_domain_knowledge(query_text, collection, model, top_k=3):\n",
    "    \"\"\"\n",
    "    Query the ChromaDB collection for relevant domain knowledge.\n",
    "    \n",
    "    Args:\n",
    "        query_text: Text to search for in the knowledge base\n",
    "        collection: ChromaDB collection containing domain knowledge\n",
    "        model: SentenceTransformer model for embeddings\n",
    "        top_k: Number of top relevant documents to retrieve (default: 3)\n",
    "    \"\"\"\n",
    "    query_embedding = embed_text(query_text)\n",
    "    results = collection.query(\n",
    "        query_embeddings=[query_embedding],\n",
    "        n_results=top_k\n",
    "    )\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bb805029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimized RAG-based function using single batch prompt with enhanced explanations and domain knowledge references\n",
    "def fill_missing_predicates_llm_with_domain_knowledge(input_df, unique_predicates, collection, model,\n",
    "                                                 output_file='llm_rag_filled_predicates.csv', \n",
    "                                                 metrics_file='llm_rag_metrics.json', \n",
    "                                                 responses_file='llm_rag_responses.json'):\n",
    "    \"\"\"\n",
    "    Use Gemini API with RAG to fill in missing predicates in DataFrame using optimized single batch prompt.\n",
    "    \n",
    "    Args:\n",
    "        input_df: DataFrame with potential missing predicates\n",
    "        unique_predicates: List of unique predicates to choose from\n",
    "        collection: ChromaDB collection for domain knowledge retrieval\n",
    "        model: SentenceTransformer model for embeddings\n",
    "        output_file: Path to save the new CSV with LLM filled predicates\n",
    "        metrics_file: Path to save metrics about the LLM usage\n",
    "        responses_file: Path to save all LLM responses for analysis\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (filled_df, metrics, responses)\n",
    "    \"\"\"\n",
    "    # Configure Gemini API\n",
    "    genai.configure(api_key=api)\n",
    "    llm_model = genai.GenerativeModel('gemini-2.5-flash')\n",
    "    \n",
    "    df = input_df.copy()\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Find all empty predicate rows\n",
    "    empty_mask = df['predicate'].isna() | (df['predicate'] == '') | (df['predicate'].str.strip() == '')\n",
    "    empty_indices = df[empty_mask].index.tolist()\n",
    "    empty_count = len(empty_indices)\n",
    "    \n",
    "    print(f\"Found {empty_count} empty predicates to fill\")\n",
    "    \n",
    "    if empty_count == 0:\n",
    "        print(\"No empty predicates found!\")\n",
    "        return df, {}, []\n",
    "    \n",
    "    # Retrieve domain knowledge for all cases and build single batch prompt\n",
    "    predicate_list = ', '.join(unique_predicates)\n",
    "    \n",
    "    # Build comprehensive batch prompt with RAG context for all cases\n",
    "    batch_prompt = f\"\"\"You are a biomedical knowledge graph expert. Complete the missing predicates for these triples using the provided domain knowledge context.\n",
    "\n",
    "Available predicates: {predicate_list}\n",
    "\n",
    "Instructions: \n",
    "1. For each numbered triple, provide ONLY the most appropriate predicate from the available list\n",
    "2. Use the provided domain knowledge context to make informed decisions\n",
    "3. Each response must include a brief explanation referencing the context that supports your choice\n",
    "4. Format: \"X. predicate_name | Explanation: [brief justification citing relevant context]\"\n",
    "\n",
    "Cases to complete:\n",
    "\"\"\"\n",
    "    \n",
    "    # Collect all contexts and build case mapping\n",
    "    case_mapping = {}\n",
    "    case_contexts = {}\n",
    "    \n",
    "    for case_num, idx in enumerate(empty_indices, 1):\n",
    "        row = df.iloc[idx]\n",
    "        case_mapping[case_num] = idx\n",
    "        \n",
    "        # Retrieve relevant domain knowledge context for this case\n",
    "        query_text = f\"relationship between {row['subject']} and {row['object']}\"\n",
    "        retrieval_results = query_domain_knowledge(query_text, collection, model, top_k=3)\n",
    "        \n",
    "        context = \"\\n\".join(retrieval_results[\"documents\"][0]) if retrieval_results[\"documents\"][0] else \"No specific context found.\"\n",
    "        case_contexts[case_num] = {\n",
    "            'context': context,\n",
    "            'subject': row['subject'],\n",
    "            'object': row['object'],\n",
    "            'query': query_text\n",
    "        }\n",
    "        \n",
    "        # Add case to batch prompt with context\n",
    "        batch_prompt += f\"\"\"\n",
    "{case_num}. Subject: {row['subject']} | Object: {row['object']}\n",
    "   Domain Context: {context[:500]}...\n",
    "   \n",
    "\"\"\"\n",
    "    \n",
    "    batch_prompt += f\"\"\"\n",
    "Expected response format:\n",
    "1. predicate_name | Explanation: Based on the context mentioning [specific reference], this predicate best describes...\n",
    "2. predicate_name | Explanation: The domain knowledge indicates [specific reference], supporting this relationship...\n",
    "...\n",
    "\n",
    "Respond with ONLY the numbered list of predicates and explanations, nothing else.\"\"\"\n",
    "\n",
    "    print(f\"Sending optimized batch request for {empty_count} predicates with RAG context...\")\n",
    "    \n",
    "    llm_filled_count = 0\n",
    "    fallback_count = 0\n",
    "    successful_requests = 0\n",
    "    failed_requests = 0\n",
    "    detailed_responses = []\n",
    "    \n",
    "    try:\n",
    "        # Single optimized API request for all missing predicates with RAG context\n",
    "        response = llm_model.generate_content(\n",
    "            batch_prompt,\n",
    "            generation_config=genai.types.GenerationConfig(\n",
    "                max_output_tokens=empty_count * 50,  # More tokens for explanations\n",
    "                temperature=0.1,  # Lower temperature for more consistent responses\n",
    "                candidate_count=1\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        response_text = response.text.strip()\n",
    "        print(\"✓ Batch RAG API request successful\")\n",
    "        successful_requests = 1\n",
    "        \n",
    "        # Parse the response to extract predicates and explanations\n",
    "        response_lines = response_text.split('\\n')\n",
    "        predicate_suggestions = {}\n",
    "        explanations = {}\n",
    "        \n",
    "        for line in response_lines:\n",
    "            line = line.strip()\n",
    "            if line and '|' in line:\n",
    "                # Match patterns like \"1. predicate_name | Explanation: ...\"\n",
    "                parts = line.split('|', 1)\n",
    "                if len(parts) == 2:\n",
    "                    predicate_part = parts[0].strip()\n",
    "                    explanation_part = parts[1].strip()\n",
    "                    \n",
    "                    # Extract case number and predicate\n",
    "                    match = re.match(r'^(\\d+)[\\.\\)\\s]+(.+)', predicate_part)\n",
    "                    if match:\n",
    "                        case_num = int(match.group(1))\n",
    "                        suggested_predicate = match.group(2).strip()\n",
    "                        \n",
    "                        # Clean up the suggestion\n",
    "                        suggested_predicate = suggested_predicate.replace('\"', '').replace(\"'\", \"\")\n",
    "                        \n",
    "                        # Try exact match first\n",
    "                        if suggested_predicate in unique_predicates:\n",
    "                            predicate_suggestions[case_num] = suggested_predicate\n",
    "                            explanations[case_num] = explanation_part\n",
    "                        else:\n",
    "                            # Try partial matching\n",
    "                            for predicate in unique_predicates:\n",
    "                                if predicate in suggested_predicate or suggested_predicate in predicate:\n",
    "                                    predicate_suggestions[case_num] = predicate\n",
    "                                    explanations[case_num] = explanation_part\n",
    "                                    break\n",
    "        \n",
    "        print(f\"✓ Successfully parsed {len(predicate_suggestions)} predicates with explanations from response\")\n",
    "        \n",
    "        # Apply the suggestions to the dataframe\n",
    "        for case_num, idx in case_mapping.items():\n",
    "            case_context = case_contexts[case_num]\n",
    "            \n",
    "            if case_num in predicate_suggestions:\n",
    "                suggested_predicate = predicate_suggestions[case_num]\n",
    "                explanation = explanations.get(case_num, \"No explanation provided\")\n",
    "                df.at[idx, 'predicate'] = suggested_predicate\n",
    "                llm_filled_count += 1\n",
    "                print(f\"✓ Row {idx}: Filled with '{suggested_predicate}' - {explanation}\")\n",
    "                \n",
    "                detailed_responses.append({\n",
    "                    'row': idx,\n",
    "                    'case_num': case_num,\n",
    "                    'subject': case_context['subject'],\n",
    "                    'object': case_context['object'],\n",
    "                    'context': case_context['context'],\n",
    "                    'suggested_predicate': suggested_predicate,\n",
    "                    'explanation': explanation,\n",
    "                    'success': True,\n",
    "                    'method': 'RAG_LLM'\n",
    "                })\n",
    "            else:\n",
    "                # Fallback to random selection\n",
    "                fallback_predicate = random.choice(unique_predicates)\n",
    "                df.at[idx, 'predicate'] = fallback_predicate\n",
    "                fallback_count += 1\n",
    "                print(f\"⚠ Row {idx}: No suggestion found, used random '{fallback_predicate}'\")\n",
    "                \n",
    "                detailed_responses.append({\n",
    "                    'row': idx,\n",
    "                    'case_num': case_num,\n",
    "                    'subject': case_context['subject'],\n",
    "                    'object': case_context['object'],\n",
    "                    'context': case_context['context'],\n",
    "                    'suggested_predicate': fallback_predicate,\n",
    "                    'explanation': \"Fallback: No valid suggestion from LLM\",\n",
    "                    'success': False,\n",
    "                    'method': 'Random_Fallback'\n",
    "                })\n",
    "        \n",
    "        # Estimate token usage\n",
    "        input_tokens = len(batch_prompt.split()) * 1.3\n",
    "        output_tokens = len(response_text.split()) * 1.3\n",
    "        \n",
    "        # Store comprehensive response details\n",
    "        responses = [{\n",
    "            'batch_request': True,\n",
    "            'total_cases': empty_count,\n",
    "            'prompt': batch_prompt,\n",
    "            'response_text': response_text,\n",
    "            'parsed_suggestions': predicate_suggestions,\n",
    "            'explanations': explanations,\n",
    "            'case_mapping': case_mapping,\n",
    "            'case_contexts': case_contexts,\n",
    "            'detailed_responses': detailed_responses,\n",
    "            'success': True,\n",
    "            'estimated_input_tokens': input_tokens,\n",
    "            'estimated_output_tokens': output_tokens,\n",
    "            'rag_enhanced': True\n",
    "        }]\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"✗ Batch RAG API request failed: {e}\")\n",
    "        failed_requests = 1\n",
    "        \n",
    "        # Fallback: fill all with random predicates\n",
    "        for idx in empty_indices:\n",
    "            fallback_predicate = random.choice(unique_predicates)\n",
    "            df.at[idx, 'predicate'] = fallback_predicate\n",
    "            fallback_count += 1\n",
    "            \n",
    "            detailed_responses.append({\n",
    "                'row': idx,\n",
    "                'suggested_predicate': fallback_predicate,\n",
    "                'explanation': f\"API Error Fallback: {str(e)}\",\n",
    "                'success': False,\n",
    "                'method': 'Error_Fallback'\n",
    "            })\n",
    "        \n",
    "        responses = [{\n",
    "            'batch_request': True,\n",
    "            'total_cases': empty_count,\n",
    "            'prompt': batch_prompt,\n",
    "            'error': str(e),\n",
    "            'success': False,\n",
    "            'fallback_used': True,\n",
    "            'detailed_responses': detailed_responses,\n",
    "            'rag_enhanced': True\n",
    "        }]\n",
    "        \n",
    "        input_tokens = len(batch_prompt.split()) * 1.3\n",
    "        output_tokens = 0\n",
    "    \n",
    "    end_time = time.time()\n",
    "    total_time = end_time - start_time\n",
    "    \n",
    "    # Create enhanced metrics summary\n",
    "    metrics = {\n",
    "        'total_empty_predicates': empty_count,\n",
    "        'llm_filled_count': llm_filled_count,\n",
    "        'fallback_count': fallback_count,\n",
    "        'successful_requests': successful_requests,\n",
    "        'failed_requests': failed_requests,\n",
    "        'total_requests': successful_requests + failed_requests,\n",
    "        'success_rate': successful_requests / (successful_requests + failed_requests) if (successful_requests + failed_requests) > 0 else 0,\n",
    "        'llm_success_rate': llm_filled_count / empty_count if empty_count > 0 else 0,\n",
    "        'total_processing_time_seconds': total_time,\n",
    "        'estimated_total_input_tokens': input_tokens,\n",
    "        'estimated_total_output_tokens': output_tokens,\n",
    "        'estimated_total_tokens': input_tokens + output_tokens,\n",
    "        'batch_processing': True,\n",
    "        'rag_enhanced': True,\n",
    "        'explanations_provided': True,\n",
    "        'speed_improvement': f\"~{empty_count}x faster than individual requests\",\n",
    "        'context_retrieval_enabled': True\n",
    "    }\n",
    "    \n",
    "    # Save files\n",
    "    df.to_csv(output_file, index=False)\n",
    "    \n",
    "    with open(metrics_file, 'w') as f:\n",
    "        json.dump(metrics, f, indent=2)\n",
    "    \n",
    "    with open(responses_file, 'w') as f:\n",
    "        json.dump(responses, f, indent=2)\n",
    "    \n",
    "    # Print comprehensive summary\n",
    "    print(f\"\\n=== Optimized RAG-Enhanced LLM Processing Complete ===\")\n",
    "    print(f\"LLM filled predicates saved to: {output_file}\")\n",
    "    print(f\"Total predicates filled by LLM: {llm_filled_count}/{empty_count}\")\n",
    "    print(f\"Fallback (random) assignments: {fallback_count}\")\n",
    "    print(f\"LLM success rate: {metrics['llm_success_rate']:.2%}\")\n",
    "    print(f\"Total processing time: {total_time:.2f} seconds\")\n",
    "    print(f\"Estimated tokens used: {int(input_tokens + output_tokens)}\")\n",
    "    print(f\"Speed improvement: ~{empty_count}x faster than individual requests!\")\n",
    "    print(f\"RAG context: ✓ Enhanced with domain knowledge\")\n",
    "    print(f\"Explanations: ✓ Provided with context references\")\n",
    "    print(f\"Metrics saved to: {metrics_file}\")\n",
    "    print(f\"Responses saved to: {responses_file}\")\n",
    "    \n",
    "    return df, metrics, responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "63ae47fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 40 empty predicates to fill\n",
      "Sending optimized batch request for 40 predicates with RAG context...\n",
      "Sending optimized batch request for 40 predicates with RAG context...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1759381609.366532  710520 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Batch RAG API request successful\n",
      "✓ Successfully parsed 40 predicates with explanations from response\n",
      "✓ Row 0: Filled with 'biolink:produces' - Explanation: T-helper cells (CL:0000576) are known to produce Interleukin-2 (IL2, NCBIGene:3553).\n",
      "✓ Row 1: Filled with 'biolink:produces' - Explanation: T-helper cells (CL:0000576) are known to produce Interleukin-2 (IL2, NCBIGene:3553).\n",
      "✓ Row 2: Filled with 'biolink:contributes_to' - Explanation: Dysregulation of calcium ions (CHEBI:30411) can contribute to the development of various cancers, including ovarian cancer (MONDO:0002012).\n",
      "✓ Row 4: Filled with 'biolink:contributes_to' - Explanation: Glucose (CHEBI:17303) is a primary metabolic fuel, and its altered metabolism is crucial for tumor (UMLS:C0040210) growth and proliferation.\n",
      "✓ Row 5: Filled with 'biolink:regulates' - Explanation: Phosphatidylinositol-3,4,5-trisphosphate (CHEBI:63631) is a signaling lipid that regulates various membrane activities, including transmembrane transporter activity (GO:0022851).\n",
      "✓ Row 7: Filled with 'biolink:has_phenotype' - Explanation: Dysregulation of AKT1 (NCBIGene:152) can lead to developmental abnormalities, including abnormal bone structure (HP:0003394).\n",
      "✓ Row 9: Filled with 'biolink:contributes_to' - Explanation: Cadherin family proteins (PANTHER.FAMILY:PTHR11935), such as E-cadherin mentioned in the context, are cell adhesion molecules that contribute to cell adhesion molecule binding (GO:0008800).\n",
      "✓ Row 10: Filled with 'biolink:has_participant' - Explanation: ETS1 (NCBIGene:2110) is a transcription factor involved in apoptosis, a process that includes mitochondrial outer membrane permeabilization (GO:0042775).\n",
      "✓ Row 12: Filled with 'biolink:subclass_of' - Explanation: CD82 Antigen (MESH:C084588) is explicitly mentioned in the context and is a known member of the Tetraspanin family (HGNC.FAMILY:180).\n",
      "✓ Row 13: Filled with 'biolink:occurs_in' - Explanation: Protein localization processes, including protein localization to vacuole (GO:0042600), typically initiate or occur within the cytosol (UBERON:0010006).\n",
      "✓ Row 18: Filled with 'biolink:directly_physically_interacts_with' - Explanation: CD9 antigen (CHEBI:44107) and CD81 antigen (CHEBI:86327) are both tetraspanins known to form complexes and physically interact.\n",
      "✓ Row 21: Filled with 'biolink:regulates' - Explanation: NFE2L2 (Nrf2, NCBIGene:4780) is a master regulator of the cellular response to oxidative stress (MESH:D052638).\n",
      "✓ Row 22: Filled with 'biolink:correlated_with' - Explanation: Diabetes mellitus (MESH:D004391) and obesity (MONDO:0005252) are highly correlated conditions, with obesity being a major risk factor for type 2 diabetes.\n",
      "✓ Row 24: Filled with 'biolink:produces' - Explanation: Activated macrophages (CL:0000170) are known to produce nitric oxide (CHEBI:5391) as an immune effector molecule.\n",
      "✓ Row 27: Filled with 'biolink:regulates' - Explanation: Calcium (CHEBI:29888) signaling plays a crucial role in regulating cell differentiation, including macrophage differentiation (GO:0030282).\n",
      "✓ Row 35: Filled with 'biolink:causes' - Explanation: Mutations in NDUFS4 (NCBIGene:707236), which is mentioned in the context, are a known genetic cause of mitochondrial complex I deficiency (HP:0025249).\n",
      "✓ Row 38: Filled with 'biolink:contributes_to' - Explanation: Estrogen (CHEBI:16238) is a known factor that contributes to the development and progression of many breast cancers (MONDO:0002025).\n",
      "✓ Row 43: Filled with 'biolink:directly_physically_interacts_with' - Explanation: DCC (NCBIGene:1800) is a receptor for Netrin-1 (CHEBI:51799), and they are known to physically interact.\n",
      "✓ Row 47: Filled with 'biolink:has_participant' - Explanation: SMAD4 (NCBIGene:8065) is a core component and participant in the assembly of SMAD protein complexes (GO:0038026).\n",
      "✓ Row 51: Filled with 'biolink:physically_interacts_with' - Explanation: Tetraspanin family proteins (HGNC.FAMILY:180) are known to associate with cholesterol (CHEBI:15355)-rich membrane microdomains.\n",
      "✓ Row 52: Filled with 'biolink:physically_interacts_with' - Explanation: Tetraspanin family proteins (HGNC.FAMILY:180) are known to associate with cholesterol (CHEBI:15355)-rich membrane microdomains.\n",
      "✓ Row 53: Filled with 'biolink:contributes_to' - Explanation: Nitric oxide (CHEBI:17489) is a key mediator and contributor to the inflammatory response (GO:0006954).\n",
      "✓ Row 58: Filled with 'biolink:directly_physically_interacts_with' - Explanation: Bax (UMLS:C0657912) and Bcl-2 (UMLS:C0235146) are well-known to physically interact in the regulation of apoptosis, as indicated by the context mentioning \"Bax\" and \"Bcl2\".\n",
      "✓ Row 60: Filled with 'biolink:occurs_in' - Explanation: Abnormal brain morphology (HP:0007437) can manifest or occur in specific brain regions like the cerebral cortex (UMLS:C1513999).\n",
      "✓ Row 62: Filled with 'biolink:has_input' - Explanation: APP (Amyloid Precursor Protein, NCBIGene:351) is the precursor from which amyloid-beta peptides are formed, thus serving as an input for amyloid-beta formation (GO:0031583).\n",
      "✓ Row 63: Filled with 'biolink:has_input' - Explanation: Calcium ions (CHEBI:16933) are a necessary input for calcium-dependent protein binding (GO:0008398) processes.\n",
      "✓ Row 66: Filled with 'biolink:has_input' - Explanation: ABC transporter family proteins (PANTHER.FAMILY:PTHR18966), such as Pgp mentioned in the context, are ATP-dependent, using ATP (CHEBI:18237) as an energy input for their function.\n",
      "✓ Row 67: Filled with 'biolink:directly_physically_interacts_with' - Explanation: CD44 Antigen (MESH:C048833) is a primary receptor for hyaluronic acid (CHEBI:18295), and they are known to physically interact.\n",
      "✓ Row 72: Filled with 'biolink:related_to' - Explanation: Human immunodeficiency virus 1 (NCBITaxon:55193) can modulate or be affected by host ubiquitin-protein ligase activity (GO:0004857), indicating a general relationship.\n",
      "✓ Row 73: Filled with 'biolink:produces' - Explanation: Nitric oxide synthase (NCIT:C3236) is the enzyme responsible for producing nitric oxide (CHEBI:31346).\n",
      "✓ Row 75: Filled with 'biolink:contributes_to' - Explanation: Uncontrolled cell proliferation (GO:0008283) is a fundamental process that contributes to cancer (MONDO:0012883) development.\n",
      "✓ Row 76: Filled with 'biolink:target_for' - Explanation: PTEN protein (PR:000049996), mentioned in the context, is a well-known tumor suppressor and a therapeutic target in glioblastoma (MONDO:0006789).\n",
      "✓ Row 77: Filled with 'biolink:occurs_in' - Explanation: Colorectal cancer (MONDO:0020679) is a type of cancer that occurs in the colon (UBERON:0001756).\n",
      "✓ Row 78: Filled with 'biolink:contributes_to' - Explanation: Glutathione transferase activity (GO:0061533), performed by enzymes like GSTP1 mentioned in the context, is the enzymatic process that contributes to glutathione conjugation (REACT:R-HSA-418594).\n",
      "✓ Row 84: Filled with 'biolink:has_participant' - Explanation: GABARAP (NCBIGene:2688) is a ubiquitin-like protein that can be a substrate or participant in ubiquitin-like protein ligase activity (GO:0038169).\n",
      "✓ Row 85: Filled with 'biolink:has_participant' - Explanation: GABARAP (NCBIGene:2688) is a ubiquitin-like protein that can be a substrate or participant in ubiquitin-like protein ligase activity (GO:0038169).\n",
      "✓ Row 86: Filled with 'biolink:related_to' - Explanation: While no direct interaction is immediately apparent from the context, CD63 antigen (CHEBI:92769) and SNAI1 (NCBIGene:6530) are both involved in cellular processes like migration, suggesting a general relationship.\n",
      "✓ Row 87: Filled with 'biolink:related_to' - Explanation: While no direct interaction is immediately apparent from the context, CD63 antigen (CHEBI:92769) and SNAI1 (NCBIGene:6530) are both involved in cellular processes like migration, suggesting a general relationship.\n",
      "✓ Row 91: Filled with 'biolink:has_participant' - Explanation: STX4 (Syntaxin 4, NCBIGene:23623), mentioned in the context, is a member of the syntaxin family and participates in vesicle docking processes, such as syntaxin-1-mediated vesicle docking (GO:0031175).\n",
      "✓ Row 96: Filled with 'biolink:contributes_to' - Explanation: Protein tyrosine kinase activity (GO:0071972) is the enzymatic activity that catalyzes and thus contributes to peptidyl-tyrosine phosphorylation (GO:0018104).\n",
      "\n",
      "=== Optimized RAG-Enhanced LLM Processing Complete ===\n",
      "LLM filled predicates saved to: gemini_rag_filled_test.csv\n",
      "Total predicates filled by LLM: 40/40\n",
      "Fallback (random) assignments: 0\n",
      "LLM success rate: 100.00%\n",
      "Total processing time: 68.21 seconds\n",
      "Estimated tokens used: 2581\n",
      "Speed improvement: ~40x faster than individual requests!\n",
      "RAG context: ✓ Enhanced with domain knowledge\n",
      "Explanations: ✓ Provided with context references\n",
      "Metrics saved to: gemini_rag_metrics_test.json\n",
      "Responses saved to: gemini_rag_responses_test.json\n",
      "RAG-enhanced LLM processing complete.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Ensure unique predicates are available\n",
    "test_df_rag = modified.copy().reset_index(drop=True)  # Reset index to 0, 1, 2, 3...\n",
    "if 'unique_predicates'in globals():\n",
    "    unique_predicates = modified['predicate'].unique()\n",
    "    unique_predicates = unique_predicates[unique_predicates != '']\n",
    "    \n",
    "    filled_df_rag, metrics_rag, responses_rag = fill_missing_predicates_llm_with_domain_knowledge(\n",
    "    test_df_rag,\n",
    "    unique_predicates,\n",
    "    collection,\n",
    "    model,\n",
    "    output_file='gemini_rag_filled_test.csv',\n",
    "    metrics_file='gemini_rag_metrics_test.json',\n",
    "    responses_file='gemini_rag_responses_test.json'\n",
    "    )\n",
    "    \n",
    "    print(\"RAG-enhanced LLM processing complete.\")\n",
    "# else:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eac405d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
